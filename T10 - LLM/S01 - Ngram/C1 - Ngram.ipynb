{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram\n",
    "\n",
    "Adapted from https://github.com/PradipKumarChaudhary1/N-gram-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_possible_word = {}\n",
    "second_possible_word = {}\n",
    "transition = {}\n",
    "\n",
    "\n",
    "def expandDict(\n",
    "    dictionary, key, value\n",
    "):  # storing into dictionary current word as a 'value' and previous word as a 'key'\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = []\n",
    "    dictionary[key].append(value)\n",
    "\n",
    "\n",
    "def get_next_probability(word_list):  # finding probability of each word\n",
    "    word_list_length = len(word_list)\n",
    "    probability_dict = {}\n",
    "    for item in word_list:\n",
    "        probability_dict[item] = (\n",
    "            probability_dict.get(item, 0) + 1\n",
    "        )  # calculating frequncy of any word\n",
    "    for (\n",
    "        key,\n",
    "        value,\n",
    "    ) in probability_dict.items():  # calculating probability and store into dictionary according to thire key and probability as a value\n",
    "        probability_dict[key] = (value + 1) / (word_list_length + 9484)\n",
    "    probability_dict = sort_prob(probability_dict)\n",
    "    return probability_dict\n",
    "\n",
    "\n",
    "def sort_prob(dictionary):  # sorting of dictionary through values\n",
    "    keys_list = list(dictionary.keys())\n",
    "    values_list = list(dictionary.values())\n",
    "    for i in range(len(values_list) - 1):\n",
    "        for j in range(len(values_list) - i - 1):\n",
    "            if values_list[j] < values_list[j + 1]:\n",
    "                temp = values_list[j]\n",
    "                values_list[j] = values_list[j + 1]\n",
    "                values_list[j + 1] = temp\n",
    "                temp = keys_list[j]\n",
    "                keys_list[j] = keys_list[j + 1]\n",
    "                keys_list[j + 1] = temp\n",
    "\n",
    "    sort_dict = {}\n",
    "    for i in range(len(values_list)):\n",
    "        sort_dict[keys_list[i]] = values_list[i]\n",
    "    return sort_dict\n",
    "\n",
    "\n",
    "def trainModel(filepath):\n",
    "    for line in open(filepath):\n",
    "        tokens = line.rstrip().lower().split()\n",
    "        tokens_length = len(tokens)\n",
    "        for i in range(tokens_length):\n",
    "            token = tokens[i]\n",
    "            if i == 0:  # if word is ffirst word of every sentence\n",
    "                first_possible_word[token] = first_possible_word.get(token, 0) + 1\n",
    "            else:\n",
    "                prev_token = tokens[i - 1]\n",
    "                if i == 1:  # if word is 2nd word of the senetnce\n",
    "                    expandDict(second_possible_word, prev_token, token)\n",
    "                if i == tokens_length - 1:  # if word is last of sentence\n",
    "                    expandDict(transition, (prev_token, token), \"END\")\n",
    "                else:\n",
    "                    prev_prev_token = tokens[i - 2]\n",
    "                    expandDict(transition, (prev_prev_token, prev_token), token)\n",
    "\n",
    "    first_possible_word_total = sum(\n",
    "        first_possible_word.values()\n",
    "    )  # finding total frequency n first_possible word\n",
    "    for (\n",
    "        key,\n",
    "        value,\n",
    "    ) in first_possible_word.items():  # calculating probability of first word in each sentence and store according to that word\n",
    "        first_possible_word[key] = (value + 1) / (first_possible_word_total + 9484)\n",
    "\n",
    "    for prev_word, next_word_list in second_possible_word.items():\n",
    "        second_possible_word[prev_word] = get_next_probability(next_word_list)\n",
    "\n",
    "    for word_pair, next_word_list in transition.items():\n",
    "        transition[word_pair] = get_next_probability(next_word_list)\n",
    "\n",
    "\n",
    "def next_word_one(tpl):\n",
    "    d = second_possible_word.get(\n",
    "        tpl\n",
    "    )  # tpl match with key and return value, value is already dictionary\n",
    "    if d is not None:\n",
    "        return list(d.keys())[:5]  # since d is already dictionary so return keys\n",
    "    else:\n",
    "        probs = np.array(list(first_possible_word.values()))\n",
    "        probs = probs / np.sum(probs)  # Make a probability distribution (sum to one)\n",
    "        return np.random.choice(\n",
    "            a=list(first_possible_word.keys()), size=5, p=probs\n",
    "        ).tolist()\n",
    "\n",
    "\n",
    "def next_word(tpl):\n",
    "    if type(tpl) is str:  # it is first word of string. return from second word\n",
    "        return next_word_one(tpl.lower())\n",
    "    if (\n",
    "        type(tpl) is tuple\n",
    "    ):  # incoming words are combination of two words. find next word now based on transitions\n",
    "        d = transition.get(tpl)\n",
    "        if d is None:\n",
    "            return next_word_one(tpl[1])\n",
    "        return list(d.keys())[:5]\n",
    "    return None  # wrong input.. return nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the path is correct.\n",
    "# curDir = os.path.join(os.getcwd(), \"T10 - LLM\", \"S01 - Ngram\")\n",
    "curDir = os.path.join(os.getcwd())\n",
    "filePath = os.path.join(curDir, \"training_text.txt\")\n",
    "print(filePath)\n",
    "\n",
    "if not os.path.exists(filePath):\n",
    "    raise FileNotFoundError(\"File not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainModel(filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting `first_possible_word`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (k, v) in enumerate(first_possible_word.items()):\n",
    "    print(f\"{k:5s}: {v:5.4f}\")\n",
    "    if idx > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting `second_possible_word`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1, (k1, v1) in enumerate(second_possible_word.items()):\n",
    "    print(k1)\n",
    "    for idx2, (k2, v2) in enumerate(v1.items()):\n",
    "        print(f\"\\t{k2:5s}: {v2:5.4f}\")\n",
    "        if idx2 > 1:\n",
    "            break\n",
    "    if idx1 > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting `transition`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1, (k1, v1) in enumerate(transition.items()):\n",
    "    print(k1)\n",
    "    for idx2, (k2, v2) in enumerate(v1.items()):\n",
    "        print(f\"\\t{k2:5s}: {v2:5.4f}\")\n",
    "        if idx2 > 1:\n",
    "            break\n",
    "    if idx1 > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startWord = \"I\"\n",
    "wordLength = 300\n",
    "\n",
    "wordList = [startWord]\n",
    "for i in range(wordLength):\n",
    "    if len(wordList) == 1:\n",
    "        res = next_word(wordList[0])\n",
    "    else:\n",
    "        res = next_word((wordList[-2], wordList[-1]))\n",
    "    wordList.append(res[0])\n",
    "\n",
    "longStr = \" \".join(wordList).replace(\" END \", \". \")\n",
    "print(textwrap.fill(longStr, width=80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
