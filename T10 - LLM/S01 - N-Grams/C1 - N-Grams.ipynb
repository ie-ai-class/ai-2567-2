{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams\n",
    "\n",
    "Adapted from https://github.com/PradipKumarChaudhary1/N-gram-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import textwrap\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_possible_word = {}\n",
    "second_possible_word = {}\n",
    "transition = {}\n",
    "\n",
    "\n",
    "def expandDict(\n",
    "    dictionary, key, value\n",
    "):  # storing into dictionary current word as a 'value' and previous word as a 'key'\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = []\n",
    "    dictionary[key].append(value)\n",
    "\n",
    "\n",
    "def get_next_probability(word_list):  # finding probability of each word\n",
    "    word_list_length = len(word_list)\n",
    "    probability_dict = {}\n",
    "    for item in word_list:\n",
    "        probability_dict[item] = (\n",
    "            probability_dict.get(item, 0) + 1\n",
    "        )  # calculating frequncy of any word\n",
    "    for (\n",
    "        key,\n",
    "        value,\n",
    "    ) in probability_dict.items():  # calculating probability and store into dictionary according to thire key and probability as a value\n",
    "        probability_dict[key] = (value + 1) / (word_list_length + 9484)\n",
    "    probability_dict = sort_prob(probability_dict)\n",
    "    return probability_dict\n",
    "\n",
    "\n",
    "def sort_prob(dictionary):  # sorting of dictionary through values\n",
    "    keys_list = list(dictionary.keys())\n",
    "    values_list = list(dictionary.values())\n",
    "    for i in range(len(values_list) - 1):\n",
    "        for j in range(len(values_list) - i - 1):\n",
    "            if values_list[j] < values_list[j + 1]:\n",
    "                temp = values_list[j]\n",
    "                values_list[j] = values_list[j + 1]\n",
    "                values_list[j + 1] = temp\n",
    "                temp = keys_list[j]\n",
    "                keys_list[j] = keys_list[j + 1]\n",
    "                keys_list[j + 1] = temp\n",
    "\n",
    "    sort_dict = {}\n",
    "    for i in range(len(values_list)):\n",
    "        sort_dict[keys_list[i]] = values_list[i]\n",
    "    return sort_dict\n",
    "\n",
    "\n",
    "def trainModel(filepath):\n",
    "    for line in open(filepath):\n",
    "        tokens = line.rstrip().lower().split()\n",
    "        tokens_length = len(tokens)\n",
    "        for i in range(tokens_length):\n",
    "            token = tokens[i]\n",
    "            if i == 0:  # if word is ffirst word of every sentence\n",
    "                first_possible_word[token] = first_possible_word.get(token, 0) + 1\n",
    "            else:\n",
    "                prev_token = tokens[i - 1]\n",
    "                if i == 1:  # if word is 2nd word of the senetnce\n",
    "                    expandDict(second_possible_word, prev_token, token)\n",
    "                if i == tokens_length - 1:  # if word is last of sentence\n",
    "                    expandDict(transition, (prev_token, token), \"END\")\n",
    "                else:\n",
    "                    prev_prev_token = tokens[i - 2]\n",
    "                    expandDict(transition, (prev_prev_token, prev_token), token)\n",
    "\n",
    "    first_possible_word_total = sum(\n",
    "        first_possible_word.values()\n",
    "    )  # finding total frequency n first_possible word\n",
    "    for (\n",
    "        key,\n",
    "        value,\n",
    "    ) in first_possible_word.items():  # calculating probability of first word in each sentence and store according to that word\n",
    "        first_possible_word[key] = (value + 1) / (first_possible_word_total + 9484)\n",
    "\n",
    "    for prev_word, next_word_list in second_possible_word.items():\n",
    "        second_possible_word[prev_word] = get_next_probability(next_word_list)\n",
    "\n",
    "    for word_pair, next_word_list in transition.items():\n",
    "        transition[word_pair] = get_next_probability(next_word_list)\n",
    "\n",
    "\n",
    "def next_word_one(tpl):\n",
    "    d = second_possible_word.get(\n",
    "        tpl\n",
    "    )  # tpl match with key and return value, value is already dictionary\n",
    "    if d is not None:\n",
    "        return list(d.keys())[:5]  # since d is already dictionary so return keys\n",
    "    else:\n",
    "        probs = np.array(list(first_possible_word.values()))\n",
    "        probs = probs / np.sum(probs)  # Make a probability distribution (sum to one)\n",
    "        return np.random.choice(\n",
    "            a=list(first_possible_word.keys()), size=5, p=probs\n",
    "        ).tolist()\n",
    "\n",
    "\n",
    "def next_word(tpl):\n",
    "    if type(tpl) is str:  # it is first word of string. return from second word\n",
    "        return next_word_one(tpl.lower())\n",
    "    if (\n",
    "        type(tpl) is tuple\n",
    "    ):  # incoming words are combination of two words. find next word now based on transitions\n",
    "        d = transition.get(tpl)\n",
    "        if d is None:\n",
    "            return next_word_one(tpl[1])\n",
    "        return list(d.keys())[:5]\n",
    "    return None  # wrong input.. return nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nnnpo\\Coding\\ai-class\\ai-2567-2\\T10 - LLM\\S01 - N-Grams\\training_text.txt\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the path is correct.\n",
    "# curDir = os.path.join(os.getcwd(), \"T10 - LLM\", \"S01 - Ngram\")\n",
    "curDir = os.path.join(os.getcwd())\n",
    "filePath = os.path.join(curDir, \"training_text.txt\")\n",
    "print(filePath)\n",
    "\n",
    "if not os.path.exists(filePath):\n",
    "    \n",
    "    target_url = \"https://github.com/ie-ai-class/ai-2567-2/raw/refs/heads/main/T10%20-%20LLM/S01%20-%20N-Grams/training_text.txt\"\n",
    "    data = urllib.request.urlopen(target_url)\n",
    "\n",
    "    with open(filePath, \"wb\") as file:\n",
    "        for line in data:\n",
    "            file.write(line)\n",
    "\n",
    "    with open(filePath) as file:\n",
    "        text = file.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "trainModel(filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting `first_possible_word`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to   : 0.0013\n",
      "i    : 0.0512\n",
      "in   : 0.0042\n",
      "it   : 0.0254\n",
      "all  : 0.0014\n",
      "he   : 0.0148\n",
      "they : 0.0035\n"
     ]
    }
   ],
   "source": [
    "for idx, (k, v) in enumerate(first_possible_word.items()):\n",
    "    print(f\"{k:5s}: {v:5.4f}\")\n",
    "    if idx > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting `second_possible_word`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "\tme   : 0.0005\n",
      "\tsherlock: 0.0002\n",
      "\tspeak: 0.0002\n",
      "i\n",
      "\thave : 0.0077\n",
      "\tam   : 0.0059\n",
      "\thad  : 0.0037\n",
      "in\n",
      "\tthe  : 0.0021\n",
      "\ta    : 0.0008\n",
      "\tthis : 0.0007\n",
      "it\n",
      "\tis   : 0.0148\n",
      "\twas  : 0.0105\n",
      "\tmust : 0.0013\n",
      "all\n",
      "\tthe  : 0.0003\n",
      "\twas  : 0.0003\n",
      "\tday  : 0.0003\n"
     ]
    }
   ],
   "source": [
    "for idx1, (k1, v1) in enumerate(second_possible_word.items()):\n",
    "    print(k1)\n",
    "    for idx2, (k2, v2) in enumerate(v1.items()):\n",
    "        print(f\"\\t{k2:5s}: {v2:5.4f}\")\n",
    "        if idx2 > 1:\n",
    "            break\n",
    "    if idx1 > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting `transition`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('woman', 'to')\n",
      "\tsherlock: 0.0002\n",
      "\thim  : 0.0002\n",
      "\tbear : 0.0002\n",
      "('to', 'sherlock')\n",
      "\tholmes: 0.0003\n",
      "('sherlock', 'holmes')\n",
      "\tEND  : 0.0010\n",
      "\twas  : 0.0010\n",
      "\ts    : 0.0008\n",
      "('holmes', 'she')\n",
      "\tcried: 0.0003\n",
      "\tis   : 0.0002\n",
      "\tused : 0.0002\n",
      "('she', 'is')\n",
      "\ta    : 0.0004\n",
      "\tnot  : 0.0004\n",
      "\tnow  : 0.0004\n"
     ]
    }
   ],
   "source": [
    "for idx1, (k1, v1) in enumerate(transition.items()):\n",
    "    print(k1)\n",
    "    for idx2, (k2, v2) in enumerate(v1.items()):\n",
    "        print(f\"\\t{k2:5s}: {v2:5.4f}\")\n",
    "        if idx2 > 1:\n",
    "            break\n",
    "    if idx1 > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have you not find me ungrateful holmes turned to the other. he was a very\n",
      "serious one to the other. has only been here. i have no doubt that the doctor s\n",
      "advice and help that is the first place we may take it that it was a very\n",
      "serious one to the other. a few minutes with his head sunk upon his face. your\n",
      "majesty. its disappearance however was but one way out of the most perfect\n",
      "reasoning and observing machine that the doctor s advice and help that is the\n",
      "first place we may take it that it was a very serious one to the other. i have\n",
      "no doubt that the doctor s advice and help that is the first place we may take\n",
      "it that it was a very serious one to the other. it is a very serious one to the\n",
      "other. he was a very serious one to the other. by the fire. i have no doubt that\n",
      "the doctor s advice and help that is the first place we may take it that it was\n",
      "a very serious one to the other. it is a very serious one to the other. and now\n",
      "i am sure that i have no doubt that the doctor s advice and help that is the\n",
      "first place we may take it that it was a very serious one to the other. to me.\n",
      "well i have no doubt that the doctor s advice and help that is the first place\n",
      "we may take it that it was a very serious one to the other. remarkable as being\n",
      "a man who is in a few minutes with his head sunk upon his\n"
     ]
    }
   ],
   "source": [
    "startWord = \"I\"\n",
    "wordLength = 300\n",
    "\n",
    "wordList = [startWord]\n",
    "for i in range(wordLength):\n",
    "    if len(wordList) == 1:\n",
    "        res = next_word(wordList[0])\n",
    "    else:\n",
    "        res = next_word((wordList[-2], wordList[-1]))\n",
    "    wordList.append(res[0])\n",
    "\n",
    "longStr = \" \".join(wordList).replace(\" END \", \". \")\n",
    "print(textwrap.fill(longStr, width=80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
