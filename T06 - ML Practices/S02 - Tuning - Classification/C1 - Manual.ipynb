{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning for classification models\n",
    "## Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "dataObj = load_breast_cancer()\n",
    "print(dataObj.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe\n",
    "df = pd.DataFrame(dataObj.data, columns=dataObj.feature_names)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataObj.data\n",
    "y = dataObj.target\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=1)\n",
    "\n",
    "# Standardization\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# Classifier\n",
    "lr = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation (Stratified K-fold)\n",
    "- Note that it is possible to get test accuracy higher than validation accuracy.\n",
    "- This might ring an alarm (i.e. too few test data as pointed out in https://stats.stackexchange.com/a/59632).\n",
    "- However, keep in mind that when using the test data, `gs.fit()` already fit to the entire training set so the amount of data that is used to train the final model is different from the amount of data used to train during grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(estimator=lr,\n",
    "                         X=X_train_std,\n",
    "                         y=y_train,\n",
    "                         cv=5,\n",
    "                         scoring=['accuracy','f1'],\n",
    "                         n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T.loc[['test_accuracy', 'test_f1'],['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter turning (manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "datas = []\n",
    "for C in Cs:\n",
    "    lr = LogisticRegression(random_state=1, C=C)\n",
    "    scores = cross_validate(\n",
    "        estimator=lr, X=X_train_std, y=y_train, cv=5, scoring=[\"accuracy\", \"f1\"], n_jobs=-1\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"C\": C,\n",
    "        \"accuracy_mean\": scores[\"test_accuracy\"].mean(),\n",
    "        \"accuracy_std\": scores[\"test_accuracy\"].std(),\n",
    "        \"f1_mean\": scores[\"test_f1\"].mean(),\n",
    "        \"f1_std\": scores[\"test_f1\"].std(),\n",
    "    }\n",
    "    datas.append(data)\n",
    "\n",
    "df = pd.DataFrame.from_dict(datas)\n",
    "df = df.sort_values(by=\"accuracy_mean\", ascending=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best C\n",
    "C_best = df.iloc[0][\"C\"]\n",
    "print(C_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=1, C=C_best, max_iter=5000) # max_iter=5000 to avoid convergence warning\n",
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual test result\n",
    "\n",
    "Note that the test accuracy can be higher than CV accuracy due to different numbers of training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_std)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_pred):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "79088bb772545dc9740b3f6fd02f1fa74686ae15b783fc1c2abf8492adb1c7fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
